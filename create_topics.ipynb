{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run ./methods.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_pickle('./data/fitbitflexwirelessactivitysleepwristbandblack.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run ./tfidf.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = []\n",
    "entities_scores = []\n",
    "phrases = []\n",
    "for index, review in df.iterrows():\n",
    "    tmp_entities = []\n",
    "    tmp_entities_scores = []\n",
    "    tmp_phrases = []\n",
    "    all_entities = review.noun_phrase_entities+review.bigram_entities+review.trigram_entities\n",
    "    all_phrases = review.noun_phrases+review.bigrams+review.trigrams\n",
    "    all_scores = review.noun_phrase_scores+review.bigrams_scores+review.trigrams_scores\n",
    "    for i, entity in enumerate(all_entities):\n",
    "        if entity != '':\n",
    "            if len(nltk.word_tokenize(all_phrases[i])) >= 2:\n",
    "                tmp_entities.append(entity)\n",
    "                tmp_entities_scores.append(all_scores[i])\n",
    "                tmp_phrases.append(all_phrases[i])\n",
    "    entities.append(tmp_entities)\n",
    "    entities_scores.append(tmp_entities_scores)\n",
    "    phrases.append(tmp_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = list(itertools.chain(*entities))\n",
    "multi_word_entities = Counter(flatten).most_common()[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_word_entities = []\n",
    "for i in range(math.ceil(len(flatten)/10000)):\n",
    "    single_word_entities.append(liteClient.getKeywords(' '.join(flatten[i*10000:(i+1)*10000])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten2 = list(itertools.chain(*single_word_entities))\n",
    "single_word_entities = Counter(flatten2).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ = 0\n",
    "for item in multi_word_entities:\n",
    "    if item[1]>max_:\n",
    "        max_ = item[1]\n",
    "multi_word_entities_normalized = []\n",
    "for item in multi_word_entities:\n",
    "    multi_word_entities_normalized.append((item[0],item[1]/max_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ = 0\n",
    "for item in single_word_entities:\n",
    "    if item[1]>max_:\n",
    "        max_ = item[1]\n",
    "single_word_entities_normalized = []\n",
    "for item in single_word_entities:\n",
    "    single_word_entities_normalized.append((item[0],item[1]/max_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entities = multi_word_entities_normalized+[entity for entity in single_word_entities_normalized if entity[0] not in flatten]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entities = [entity for entity in all_entities if entity[0] !='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_entities = np.zeros(1000)\n",
    "dist = 0.9\n",
    "while len(final_entities)>int(math.log2(len(df))):\n",
    "    all_entities_sorted_by_weight = sorted(all_entities, key=lambda tup: tup[1], reverse=True)\n",
    "    list1 = all_entities_sorted_by_weight[:]\n",
    "    list2 = all_entities_sorted_by_weight[:]\n",
    "    final_entities = []\n",
    "    while list1:\n",
    "        items1 = list1[0]\n",
    "        x = None\n",
    "        for items2 in list2:\n",
    "            try:\n",
    "                if items1 != items2:\n",
    "                    if cosinus_distance(get_phrase_vec(items1[0]),get_phrase_vec(items2[0]))>dist:\n",
    "                        if x:\n",
    "                            x = (x[0]+[items2[0]], x[1]+items2[1])\n",
    "                        else:\n",
    "                            x = ([items1[0],items2[0]], items1[1]+items2[1])\n",
    "                        list2.remove(items2)\n",
    "                        list1.remove(items2)\n",
    "            except:\n",
    "                pass\n",
    "        if x:\n",
    "            final_entities.append(x)\n",
    "        else:\n",
    "            final_entities.append(([items1[0]],items1[1]))\n",
    "        list1.remove(items1)\n",
    "        list2.remove(items1)\n",
    "    dist-=0.05\n",
    "    if dist <= 0.4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_final_entities = sorted(final_entities, key=lambda tup: tup[1], reverse=True)[:int(math.log2(len(df)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_final_entities_headline = []\n",
    "replacements = []\n",
    "for tuple in sorted_final_entities:\n",
    "    best_topic = ''\n",
    "    best_topic_score = -1\n",
    "    for item in tuple[0]:\n",
    "        try:\n",
    "            score = sum([d[word]for word in item.split()])*Counter(flatten)[item]\n",
    "            if score>best_topic_score:\n",
    "                best_topic=item\n",
    "                best_topic_score=score\n",
    "        except:\n",
    "            pass\n",
    "    replacements.append([best_topic,tuple[0]])\n",
    "    sorted_final_entities_headline.append((best_topic,tuple[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['battery life',\n",
       "  ['charge',\n",
       "   'battery',\n",
       "   'battery life',\n",
       "   'charger',\n",
       "   'battery charge',\n",
       "   'charge hour']],\n",
       " ['step', ['step', 'k step', 'track step', 'step goal', 'measure']],\n",
       " ['sleep mode',\n",
       "  ['sleep',\n",
       "   'sleep mode',\n",
       "   'sleep pattern',\n",
       "   'sleep tracker',\n",
       "   'sleep function',\n",
       "   'activity sleep',\n",
       "   'sleep habit',\n",
       "   'sleep activity',\n",
       "   'sleep log',\n",
       "   'sleep quality',\n",
       "   'sleep cycle']],\n",
       " ['band',\n",
       "  ['band',\n",
       "   'wrist band',\n",
       "   'replacement band',\n",
       "   'rubber band',\n",
       "   'band clasp',\n",
       "   'color band']],\n",
       " ['sleep track',\n",
       "  ['track',\n",
       "   'sleep track',\n",
       "   'track sleep',\n",
       "   'track activity',\n",
       "   'way track',\n",
       "   'track food']],\n",
       " ['customer service',\n",
       "  ['customer service', 'customer', 'email', 'service', 'company', 'warranty']],\n",
       " ['time', ['time', 'sleep time', 'couple time']],\n",
       " ['flex', ['flex', 'flex flex', 'flex activity']],\n",
       " ['e g', ['e g', 'etc']],\n",
       " ['work', ['work', 'flex work']],\n",
       " ['activity',\n",
       "  ['activity',\n",
       "   'activity tracker',\n",
       "   'activity level',\n",
       "   'exercise',\n",
       "   'movement',\n",
       "   'arm movement',\n",
       "   'activity monitor']]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for replacement in replacements:\n",
    "    entities = [[replacement[0] if entity in replacement[1] else entity for entity in review_ents] for review_ents in entities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['topic_entities'] = entities\n",
    "df['topic_entities_scores'] = entities_scores\n",
    "df['topic_phrases'] = phrases\n",
    "#df.to_pickle('./data/fitbitflexwirelessactivitysleepwristbandblack.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = 'data/fitbitflexwirelessactivitysleepwristbandblack.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_filename = filename[:-5]+'_topics.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(topics_filename, 'wb') as f:\n",
    "    pickle.dump([topic[0] for topic in sorted_final_entities_headline], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_pickle(\"data/sonymdr7506professionallargediaphragmheadphone.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"data/sonymdr7506professionallargediaphragmheadphone_topics.pkl\", 'wb') as f:\n",
    "#    pickle.dump([topic[0] for topic in sorted_final_entities_headline], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten1 = list(itertools.chain(*topic_phrases))\n",
    "#flatten2 = list(itertools.chain(*topic_entities_scores))\n",
    "#d = {'np': flatten1, 'score': flatten2}\n",
    "#lel = pd.DataFrame(data=d)\n",
    "#lel = lel.drop_duplicates()\n",
    "#lel.sort_values(by=['score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:textmining]",
   "language": "python",
   "name": "conda-env-textmining-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
