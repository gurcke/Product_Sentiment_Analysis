{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import scrapy\n",
    "import re\n",
    "import dateparser\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import unicodedata\n",
    "import nltk\n",
    "import re\n",
    "import textacy\n",
    "import contractions\n",
    "import itertools\n",
    "import json\n",
    "import retinasdk\n",
    "import pyLDAvis.gensim\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from gensim import corpora, models\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from keras.models import model_from_json\n",
    "from scipy import spatial\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from twisted.internet import reactor, defer\n",
    "from scrapy.crawler import CrawlerRunner\n",
    "from scrapy.utils.log import configure_logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper method to remove all html tags\n",
    "def cleanhtml(raw_html):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return cleantext\n",
    "\n",
    "def cleanhelpfulvotes(votes_string):\n",
    "    vote = votes_string.partition(\" \")[0]\n",
    "    if vote == 'One':\n",
    "        vote = '1'\n",
    "    elif len(vote) > 3:\n",
    "        vote = vote.replace(\",\", \"\")\n",
    "    return int(vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variables set by the first crawler\n",
    "image_src = ''\n",
    "reviews_Link = ''\n",
    "filename = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewNavSpider(scrapy.Spider):\n",
    "    name = 'reviewspider'\n",
    "    start_urls = [\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        global image_src\n",
    "        global reviews_Link\n",
    "        review_dict = []\n",
    "        image_src = response.xpath('//img[contains(@id, \"landingImage\")]/@data-old-hires')\n",
    "        image_src = image_src.extract()[0]\n",
    "        reviews_Link = response.xpath('//a[contains(@data-hook, \"see-all-reviews-link-foot\")]/@href')\n",
    "        reviews_Link = \"https://www.amazon.com\"+reviews_Link.extract()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewSpider(scrapy.Spider):\n",
    "    name = 'reviewspider'\n",
    "    start_urls = []\n",
    "    \n",
    "    def parse(self, response):\n",
    "        review_dict = []\n",
    "        reviews = response.xpath('//div[@data-hook=\"review\"]')\n",
    "        article = response.xpath(\n",
    "            '//div[contains(@class, \"a-row product-title\")]//a[contains(@data-hook, \"product-link\")]/text()'\n",
    "        ).extract()\n",
    "        price = response.xpath(\n",
    "            '//span[contains(@class, \"a-color-price arp-price\")]/text()'\n",
    "        ).extract()\n",
    "        for review in reviews:\n",
    "            review_title = review.xpath(\n",
    "                './/a[contains(@data-hook, \"review-title\")]/text()').extract()\n",
    "            review_rating = review.xpath(\n",
    "                './/i[contains(@data-hook, \"review-star-rating\")]/span[contains(@class, \"a-icon-alt\")]/text()'\n",
    "            ).extract()\n",
    "            review_date = review.xpath(\n",
    "                './/span[contains(@data-hook, \"review-date\")]/text()').extract(\n",
    "                )\n",
    "            review_body = review.xpath(\n",
    "                './/span[contains(@data-hook, \"review-body\")]').extract()\n",
    "            review_helpful_votes = review.xpath(\n",
    "                './/span[contains(@data-hook, \"helpful-vote-statement\")]/text()'\n",
    "            ).extract()\n",
    "            review_source = review.xpath(\n",
    "                './/a[contains(@data-hook, \"review-title\")]/@href').extract()\n",
    "            review = {\n",
    "                \"article\":\n",
    "                article[0],\n",
    "                \"price\":\n",
    "                float(price[0].strip().lstrip('$')),\n",
    "                \"review_title\":\n",
    "                review_title[0],\n",
    "                \"review_rating\":\n",
    "                int(review_rating[0][0]),\n",
    "                \"review_date\":\n",
    "                dateparser.parse(review_date[0]).strftime('%Y-%m-%d'),\n",
    "                \"review_body\":\n",
    "                cleanhtml(review_body[0]),\n",
    "                \"review_helpful_votes\":\n",
    "                cleanhelpfulvotes(review_helpful_votes[0])\n",
    "                if review_helpful_votes else 0,\n",
    "                \"review_source\":\n",
    "                \"https://www.amazon.com\" + review_source[0]\n",
    "            }\n",
    "            review_dict.append(review)\n",
    "        global filename\n",
    "        filename = \"data/{}.json\".format(re.sub('[^a-zA-z0-9]', '', article[0]).lower())\n",
    "        if not os.path.isfile(filename):\n",
    "            with open(filename, mode='w') as f:\n",
    "                f.write(json.dumps([]))\n",
    "        with open(filename) as feedsjson:\n",
    "            feeds = json.load(feedsjson)\n",
    "            feeds.append(review_dict)\n",
    "        with open(filename, mode='w') as f:\n",
    "            f.write(json.dumps(feeds))\n",
    "        yield response.follow(\n",
    "            \"https://www.amazon.com\" +\n",
    "            response.xpath('//li[@class=\"a-last\"]/a/@href').extract()[0],\n",
    "            callback=self.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%capture\n",
    "# crawl sequentially\n",
    "configure_logging()\n",
    "runner = CrawlerRunner({\n",
    "    'DOWNLOAD_DELAY':\n",
    "    '2',\n",
    "    'CONCURRENT_REQUESTS':\n",
    "    '1',\n",
    "    'CONCURRNT_REQUESTS_PER_IP':\n",
    "    '1'\n",
    "})\n",
    "\n",
    "@defer.inlineCallbacks\n",
    "def crawl(start_url):\n",
    "    spider1.start_urls.append(start_url)\n",
    "    yield runner.crawl(ReviewNavSpider)\n",
    "    spider2.start_urls.append(reviews_Link+'&pageNumber=1')\n",
    "    yield runner.crawl(spider2)\n",
    "    reactor.stop()\n",
    "    \n",
    "spider1 = ReviewNavSpider()\n",
    "spider2 = ReviewSpider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start_url = 'https://www.amazon.com/dp/B00BGO0Q9O/ref=twister_B00BR00AWU?th=1'\n",
    "#crawl(start_url)\n",
    "#reactor.run()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python [conda env:textmining]",
   "language": "python",
   "name": "conda-env-textmining-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 476.85,
   "position": {
    "height": "498.85px",
    "left": "431px",
    "right": "16px",
    "top": "-11px",
    "width": "800px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
