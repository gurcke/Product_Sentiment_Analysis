{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run ./methods.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_pickle('./data/fitbitflexwirelessactivitysleepwristbandblack.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run ./tfidf.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add and remove stopwords\n",
    "stopwords = ['iphone', 'fitbit', 'alta', 'fit bit', 'hr', 'sony', 'mdr', 'mdr7506', 'product', 'device', 'thing', 'love','daughter','son','husband','wife','mother','father','star','pair','thing','product','mom','dad','day','week','month','year','minute','second']\n",
    "no_stopwords = ['no', 'not']\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "for stopword in stopwords:\n",
    "    stopword_list.append(stopword)\n",
    "for no_stopword in no_stopwords:\n",
    "    stopword_list.remove(no_stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_tokens = list(itertools.chain(*tokens))\n",
    "\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "bigram_finder = nltk.collocations.BigramCollocationFinder.from_words(merged_tokens)\n",
    "trigram_finder = nltk.collocations.TrigramCollocationFinder.from_words(merged_tokens)\n",
    "\n",
    "bigram_finder.apply_freq_filter(5)\n",
    "trigram_finder.apply_freq_filter(5)\n",
    "\n",
    "trigram_scores = {}\n",
    "for key, value in trigram_finder.ngram_fd.items():\n",
    "    freq = trigram_finder.score_ngram(trigram_measures.raw_freq,key[0],key[1],key[2])\n",
    "    pmi =  trigram_finder.score_ngram(trigram_measures.pmi,key[0],key[1],key[2])\n",
    "    trigram_scores[' '.join(key)]=freq*pmi*sum([len(key[0]),len(key[1]),len(key[2])])\n",
    "    \n",
    "bigram_scores = {}\n",
    "for key, value in bigram_finder.ngram_fd.items():\n",
    "    freq = bigram_finder.score_ngram(bigram_measures.raw_freq,key[0],key[1])\n",
    "    pmi =  bigram_finder.score_ngram(bigram_measures.pmi,key[0],key[1])\n",
    "    bigram_scores[' '.join(key)]=freq*pmi*sum([len(key[0]),len(key[1])])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams = sorted(trigram_scores, key=trigram_scores.get, reverse=True)[:len(df.noun_phrases)]\n",
    "bigrams = sorted(bigram_scores, key=bigram_scores.get, reverse=True)[:len(df.noun_phrases)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract noun chunks from sentences and clear\n",
    "reviews_trigrams = []\n",
    "reviews_bigrams = []\n",
    "trigram_entities = []\n",
    "bigram_entities = []\n",
    "for review in df.preprocessed:\n",
    "    \n",
    "    review = preprocess(\n",
    "            review,\n",
    "            isolate_special_characters=True,\n",
    "            remove_special_characters=True,\n",
    "            remove_extra_whitespace=True,\n",
    "            remove_stopwords=True,\n",
    "            remove_numbers=True)\n",
    "    \n",
    "    tmp_trigrams = []\n",
    "    tmp_trigram_entities = []\n",
    "    tmp_bigram_entities = []\n",
    "    for trigram in trigrams:\n",
    "        if trigram in review:\n",
    "            tmp_trigrams.append(trigram)\n",
    "            trigram = extract_entity(trigram)\n",
    "            tmp_trigram_entities.append(trigram)\n",
    "    reviews_trigrams.append(tmp_trigrams)\n",
    "    trigram_entities.append(tmp_trigram_entities)\n",
    "    \n",
    "    tmp_bigrams = []\n",
    "    for bigram in bigrams:\n",
    "        if bigram in review:\n",
    "            tmp_bigrams.append(bigram)\n",
    "            bigram = extract_entity(bigram)\n",
    "            tmp_bigram_entities.append(bigram)\n",
    "    reviews_bigrams.append(tmp_bigrams)\n",
    "    bigram_entities.append(tmp_bigram_entities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_scores_ = []\n",
    "for i,review in enumerate(bigram_entities):\n",
    "    tmp_topic = []\n",
    "    for j,ph in enumerate(review):\n",
    "        try:\n",
    "            tmp_topic.append((sum([d[preprocess(word, lemmatize=True)]for word in ph.split()])/len(ph.split()))*len(reviews_bigrams[i][j].split()))\n",
    "        except:\n",
    "            tmp_topic.append(None)\n",
    "    bigram_scores_.append(tmp_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_scores_ = []\n",
    "for i,review in enumerate(trigram_entities):\n",
    "    tmp_topic = []\n",
    "    for j,ph in enumerate(review):\n",
    "        try:\n",
    "            tmp_topic.append((sum([d[preprocess(word, lemmatize=True)]for word in ph.split()])/len(ph.split()))*len(reviews_trigrams[i][j].split()))\n",
    "        except:\n",
    "            tmp_topic.append(None)\n",
    "    trigram_scores_.append(tmp_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bigrams\"] = reviews_bigrams\n",
    "df[\"bigrams_scores\"] = bigram_scores_\n",
    "df[\"trigrams\"] = reviews_trigrams\n",
    "df[\"trigrams_scores\"] = trigram_scores_\n",
    "df[\"bigram_entities\"] = bigram_entities\n",
    "df[\"trigram_entities\"] = trigram_entities\n",
    "#df.to_pickle('./data/fitbitflexwirelessactivitysleepwristbandblack.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:textmining]",
   "language": "python",
   "name": "conda-env-textmining-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
